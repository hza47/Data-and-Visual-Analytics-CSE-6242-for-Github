---
title: 'Homework4: Regression Practice'

output:
  pdf_document: default
  html_notebook: default
subtitle: |-
  CSE6242 - Data and Visual Analytics - Spring 2018

---
_GTUser:vchugh3_

---
```{r setup, include=FALSE}
setwd("C:/Users/vchugh/Documents/Academics/Georgia Tech/Spring 2018/CS 6242 Data and Visual Analytics/Assignments/HW4/")
knitr::opts_chunk$set(echo = TRUE)
library(Rmisc)
library(ggplot2)
```

0. Pre-processing the data
```{r Data Preprocessing}
start_time <- Sys.time()
setwd("C:/Users/vchugh/Documents/Academics/Georgia Tech/Spring 2018/CS 6242 Data and Visual Analytics/Assignments/HW3/mnist/mnist")
training_set <- read.csv ('mnist_train.csv', header = FALSE)
test_set <- read.csv ('mnist_test.csv', header = FALSE)

# Partitioning the training dataset
train_0_1 <- training_set[,((training_set[785,] == 0) | (training_set[785,] == 1))]
train_3_5 <- training_set[,((training_set[785,] == 3) | (training_set[785,] == 5))]

# Partitioning the testing dataset
test_0_1 <- test_set[,((test_set[785,] == 0) | (test_set[785,] == 1))]
test_3_5 <- test_set[,((test_set[785,] == 3) | (test_set[785,] == 5))]

#Shuffling the train datasets
#train_0_1 <- train_0_1[,sample(ncol(train_0_1))]
#train_3_5 <- train_3_5[,sample(ncol(train_3_5))]

#sprintf("Dimensions of train_0_1 are %i x %i", dim(train_0_1)[1], dim(train_0_1)[2])
#sprintf("Dimensions of train_3_5 are %i x %i", dim(train_3_5)[1], dim(train_3_5)[2])
#sprintf("Dimensions of test_0_1 are %i x %i", dim(test_0_1)[1], dim(test_0_1)[2])
#sprintf("Dimensions of test_3_5 are %i x %i", dim(test_3_5)[1], dim(test_3_5)[2])

# Remove the last Row from each of the data frames created.
train_data_0_1 <- train_0_1[1:784,]
train_data_3_5 <- train_3_5[1:784,]
test_data_0_1 <- test_0_1[1:784,]
test_data_3_5 <- test_3_5[1:784,]
train_labels_0_1 <- train_0_1[785,]
train_labels_3_5 <- train_3_5[785,]
test_labels_0_1 <- test_0_1[785,]
test_labels_3_5 <- test_3_5[785,]

#Transpose of the training and test data
train_data_0_1 <- t(train_data_0_1)
train_data_3_5 <- t(train_data_3_5)
test_data_0_1 <- t(test_data_0_1)
test_data_3_5 <- t(test_data_3_5)

#Add a bias term
train_data_0_1 <- data.frame (matrix(1, ncol = 1, nrow = dim(train_data_0_1)[1]), train_data_0_1)
train_data_3_5 <- data.frame (matrix(1, ncol = 1, nrow = dim(train_data_3_5)[1]), train_data_3_5)
test_data_0_1 <- data.frame (matrix(1, ncol = 1, nrow = dim(test_data_0_1)[1]), test_data_0_1)
test_data_3_5 <- data.frame (matrix(1, ncol = 1, nrow = dim(test_data_3_5)[1]), test_data_3_5)

#Convert Data to Matrix
train_data_0_1 <- as.matrix(train_data_0_1)
train_data_3_5 <- as.matrix(train_data_3_5)
test_data_0_1 <- as.matrix(test_data_0_1)
test_data_3_5 <- as.matrix(test_data_3_5)

#Transpose of the data
train_labels_0_1 <- t(train_labels_0_1)
train_labels_3_5 <- t(train_labels_3_5)
test_labels_0_1 <- t(test_labels_0_1)
test_labels_3_5 <- t(test_labels_3_5)

#Map training labels to 0 and 1
train_labels_0_1 <- ifelse(train_labels_0_1 == 0 ,-1,1)
train_labels_3_5 <- ifelse(train_labels_3_5 == 3 ,-1,1)
test_labels_0_1 <- ifelse(test_labels_0_1 == 0 ,-1,1)
test_labels_3_5 <- ifelse(test_labels_3_5 == 3 ,-1,1)

```


1 and 2. Implementation and Modeling [35 points and 35 Points]

```{r Implemenmtation and Modeling}
####################################
#####Define the sigmoid function
####################################
sigmoid <- function(z)
{
gz <- 1/(1+exp(-z))
return(gz)
}

####################################
#####Predict y
####################################
predict <- function(theta, data){
prediction <- sigmoid(data %*% theta)
prediction <- ifelse(prediction>0.5,1,-1)
return (prediction)
}

####################################
#####Calculate the accuracy
####################################
 accuracy = function(labels_pred, labels){
    error = labels - labels_pred
    acc = length(error[error==0])/length(labels)
    return(acc)
  }
 
#############################################
#####Calculate stochastic Gradient Descent
#############################################
calculate_gradient_descent_sgd <- function (x, y, epochs, alpha, threshold) {

#Initialize theta to random values.
theta <- runif(dim(x)[2], min=0, max=1)
theta <- as.matrix(theta)
temp = theta
number_of_samples = dim(x)[1]

# For every epoch, do the following, I need to check for convergance every epoch. Also, I need to run through all the data in every epoch.
for(epoch in 1:epochs) {
 #For every epoch, shuffle the dataset.
 #Bind X and Y so that we can shuffle X and Y equally
 temp_binded_df <- cbind(x, y)

 #shuffle X and Y equally by row
 shuffled_df <- temp_binded_df[sample(nrow(temp_binded_df)),]

 #unbind X and Y after the shuffling is done
 xtemp <- shuffled_df[,1:785]
 ytemp <- shuffled_df[,786]
 ytemp <- as.matrix(ytemp)
 #Now I am done with shuffling the dataset for this epoch.
 
 #Save Previous theta value. Previous value should be for every epoch.
 theta_previous = theta
 
 #Iterate over each sample in the dataset
 for (i in 1:number_of_samples)
 {
   xi <- t(as.matrix(xtemp[i,]))
   yi <- t(as.matrix(ytemp[i,]))

   n = alpha / ((exp(yi * (xi %*% theta)) + 1))
   theta = theta + (as.numeric(n) * t(xi) %*% yi)
 }
 
 delta = sum(abs(theta_previous - theta))
 #print(delta)
 
 #Stopping condition if delta in theta is less than threshold
 if (delta < threshold) {return(theta)}
}
return(theta)
}


##################################################
#####Train SGD
##################################################
train <- function(data, labels, alpha){
theta <- calculate_gradient_descent_sgd(data, labels, 8, alpha, 0.1)
return (theta)
}

#############################################################
################Call the train function for the dataset test_data_0_1
#############################################################
theta <- train(train_data_0_1, train_labels_0_1, 0.2)
prediction <- predict(theta, test_data_0_1)
acc <- accuracy(prediction, test_labels_0_1)
sprintf("Accuracy of prediction in test_data_0_1 is %f", acc)

###################################################
#Function to rotate the image
###################################################
rotate <- function(x) t(apply(x, 2, rev))

#######################################################################
#Hardcoding matches and mismatches image generation for test_labels_0_1
#######################################################################
matches <- which(prediction == test_labels_0_1)
#Image 1 for match from dataset 0_1
temp <- t(test_data_0_1)
image0_mat <- rotate(matrix(unlist(temp[2:785,matches[1]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Expected Data 0 and Predicted Data 0")

#Image 2 for match from dataset 0_1
image0_mat <- rotate(matrix(unlist(temp[2:785,matches[1000]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Expected Data 1 and Predicted Data 1")

mismatches <- which(prediction != test_labels_0_1)
#Image 1 for mismatch from dataset 0_1
image0_mat <- rotate(matrix(unlist(temp[2:785,mismatches[1]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Expected Data 0 and Predicted Data 1")

#Image  for mismatch from dataset 0_1
image0_mat <- rotate(matrix(unlist(temp[2:785,1626]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Expected Data 1 and Predicted Data 0")

#Call the train function for the dataset train_labels_3_5
theta <- train(train_data_3_5, train_labels_3_5, 0.2)
prediction <- predict(theta, test_data_3_5)
acc <- accuracy(prediction, test_labels_3_5)
sprintf("Accuracy of prediction in test_data_3_5 is %f", acc)

#######################################################################
#Hardcoding matches and mismatches image generation for test_data_3_5
#######################################################################
matches <- which(prediction == test_labels_3_5)
temp <- t(test_data_3_5)

#Image 1 for match from dataset 3_5
image0_mat <- rotate(matrix(unlist(temp[2:785,matches[2]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Example1: Expected Data 3 and Predicted Data 3")

#Image 2 for match from dataset 3_5
image0_mat <- rotate(matrix(unlist(temp[2:785,matches[1001]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Example2: Expected Data 5 and Predicted Data 5")

mismatches <- which(prediction != test_labels_3_5)
#Image 1 for mismatch from dataset 3_5
image0_mat <- rotate(matrix(unlist(temp[2:785,mismatches[1]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Example3: Expected Data 3 and Predicted Data 5")

#Image 2 for mismatch from dataset 3_5
image0_mat <- rotate(matrix(unlist(temp[2:785,mismatches[62]]), nrow = 28, byrow = FALSE))
image(z = image0_mat, col = gray(0:255/255))
title("Example3: Expected Data 5 and Predicted Data 3")



#######################################################################
#Train and evaluate a model.
#######################################################################
model <- function(train_data, train_labels, test_data, test_labels, alpha){
result <- list()
theta <- train(train_data,train_labels,alpha)
prediction_train <- predict(theta,train_data)

train_acc = accuracy(train_labels,prediction_train)
result[1] = train_acc
prediction_test <- predict(theta,test_data)

test_acc = accuracy(test_labels,prediction_test)
result[2] = test_acc
return (result)
print (result)
}

#######################################################################
# Create a data frame with accuracies for different learning rates
#######################################################################
learning_rates <- seq(0.1, 1, by = 0.1)

accuracies_df <- as.data.frame(matrix(ncol = 3, nrow = 120))
x <- c("alpha", "mode", "accuracy")
colnames(accuracies_df) <- x

start_time <- Sys.time()

i = 1;
for (alpha in learning_rates)
{
 for (j in 1:3)
 {   
 accuracies_df$alpha[i] = alpha
 result_0_1 <- model(train_data_0_1, train_labels_0_1, test_data_0_1, test_labels_0_1, alpha)
 accuracies_df$mode[i] = "train_accuracy_0_1"
 accuracies_df$accuracy[i] = result_0_1[1]
 i = i + 1
 
 accuracies_df$alpha[i] = alpha
 accuracies_df$mode[i] = "test_accuracy_0_1"
 accuracies_df$accuracy[i] = result_0_1[2]
 i = i + 1
 
 accuracies_df$alpha[i] = alpha
 result_3_5 <- model(train_data_3_5, train_labels_3_5, test_data_3_5, test_labels_3_5, alpha)
 accuracies_df$mode[i] = "train_accuracy_3_5"
 accuracies_df$accuracy[i] = result_3_5[1]
 i = i + 1
 
 accuracies_df$alpha[i] = alpha
 accuracies_df$mode[i] = "test_accuracy_3_5"
 accuracies_df$accuracy[i] = result_3_5[2]
 i = i + 1
 }
}
end_time <- Sys.time()
end_time - start_time
accuracies_df$accuracy <- as.numeric(accuracies_df$accuracy)
accuracies_df_summary <- summarySE(accuracies_df, measurevar="accuracy", groupvars=c("mode","alpha"))
ggplot(accuracies_df_summary, aes(x=alpha, y=accuracy, colour=mode)) + geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) + geom_line() + geom_point() + ggtitle("Test and Training Accuracy vs Learning Rate")

sprintf("Maximum training accuracy for 0_1 dataset is %f", max(accuracies_df$accuracy[accuracies_df$mode == 'train_accuracy_0_1']))
sprintf("Maximum test accuracy for 0_1 dataset is %f", max(accuracies_df$accuracy[accuracies_df$mode == 'test_accuracy_0_1']))
sprintf("Maximum training accuracy for 3_5 dataset is %f", max(accuracies_df$accuracy[accuracies_df$mode == 'train_accuracy_3_5']))
sprintf("Maximum test accuracy for 3_5 dataset is %f", max(accuracies_df$accuracy[accuracies_df$mode == 'test_accuracy_3_5']))

```
3. Learning Curves [30 Points]

```{r Learning Curves}

# We create a ratio for dividing the dataset
data_ratio <- seq(0.1, 1, by = 0.1)
alpha = 0.1
accuracies_vs_datasize_df_0_1 <- as.data.frame(matrix(ncol = 3, nrow = 60))
accuracies_vs_datasize_df_3_5 <- as.data.frame(matrix(ncol = 3, nrow = 60))

x <- c("ratio", "mode", "accuracy")
colnames(accuracies_vs_datasize_df_0_1) <- x
colnames(accuracies_vs_datasize_df_3_5) <- x
i = 0;

#Shuffle the dataset
temp_binded_df_0_1 <- cbind(train_data_0_1, train_labels_0_1)
temp_binded_df_3_5 <- cbind(train_data_3_5, train_labels_3_5)

for (ratio in data_ratio) {

#shuffle X and Y equally by row
shuffled_df_0_1 <- temp_binded_df_0_1[sample(nrow(temp_binded_df_0_1)),]
shuffled_df_3_5 <- temp_binded_df_3_5[sample(nrow(temp_binded_df_3_5)),]

#unbind X and Y after the shuffling is done
train_data_0_1_shuffled <- shuffled_df_0_1[,1:785]
train_labels_0_1_shuffled <- shuffled_df_0_1[,786]
train_labels_0_1_shuffled <- as.matrix(train_labels_0_1_shuffled)

train_data_3_5_shuffled <- shuffled_df_3_5[,1:785]
train_labels_3_5_shuffled <- shuffled_df_3_5[,786]
train_labels_3_5_shuffled <- as.matrix(train_labels_3_5_shuffled)

train_data_0_1_subset <- train_data_0_1_shuffled[1:nrow(train_data_0_1_shuffled)*ratio,]
train_labels_0_1_subset <- train_labels_0_1_shuffled[1:nrow(train_labels_0_1_shuffled)*ratio,]
train_data_3_5_subset <- train_data_3_5_shuffled[1:nrow(train_data_3_5_shuffled)*ratio,]
train_labels_3_5_subset <- train_labels_3_5_shuffled[1:nrow(train_labels_3_5_shuffled)*ratio,]

 for (j in 1:3)
 {   
 #Accuracy results from sample data 0_1 dataset
 result_0_1_subset <- model(train_data_0_1_subset, train_labels_0_1_subset, test_data_0_1,  test_labels_0_1, alpha)
 result_3_5_subset <- model(train_data_3_5_subset, train_labels_3_5_subset, test_data_3_5,  test_labels_3_5, alpha)

  i = i+ 1
 accuracies_vs_datasize_df_0_1$ratio[i] = ratio
 accuracies_vs_datasize_df_0_1$mode[i] = "train_accuracy_0_1"
 accuracies_vs_datasize_df_0_1$accuracy[i] = result_0_1_subset[1]
 accuracies_vs_datasize_df_3_5$ratio[i] = ratio
 accuracies_vs_datasize_df_3_5$mode[i] = "train_accuracy_3_5"
 accuracies_vs_datasize_df_3_5$accuracy[i] = result_3_5_subset[1]

 i = i+ 1
 accuracies_vs_datasize_df_0_1$ratio[i] = ratio
 accuracies_vs_datasize_df_0_1$mode[i] = "test_accuracy_0_1"
 accuracies_vs_datasize_df_0_1$accuracy[i] = result_0_1_subset[2]
 accuracies_vs_datasize_df_3_5$ratio[i] = ratio
 accuracies_vs_datasize_df_3_5$mode[i] = "test_accuracy_3_5"
 accuracies_vs_datasize_df_3_5$accuracy[i] = result_3_5_subset[2]
 }
}

accuracies_vs_datasize_df_0_1$accuracy <- as.numeric(accuracies_vs_datasize_df_0_1$accuracy)
accuracies_vs_datasize_df_0_1_summary <- summarySE(accuracies_vs_datasize_df_0_1, measurevar="accuracy", groupvars=c("mode","ratio"))
ggplot(accuracies_vs_datasize_df_0_1_summary, aes(x=ratio, y=accuracy, colour=mode)) + geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) + geom_line() + geom_point() + ggtitle("Accuracy of prediction vs Learning Data Size for 0_1") + xlab("Ratio of Data Used for Training") + ylab("Accuracy")

accuracies_vs_datasize_df_3_5$accuracy <- as.numeric(accuracies_vs_datasize_df_3_5$accuracy)
accuracies_vs_datasize_df_3_5_summary <- summarySE(accuracies_vs_datasize_df_3_5, measurevar="accuracy", groupvars=c("mode","ratio"))
ggplot(accuracies_vs_datasize_df_3_5_summary, aes(x=ratio, y=accuracy, colour=mode)) + geom_errorbar(aes(ymin=accuracy-se, ymax=accuracy+se), width=.1) + geom_line() + geom_point() + ggtitle("Accuracy of prediction vs Learning Data Size for 3_5") + xlab("Ratio of Data Used for Training") + ylab("Accuracy")
end_time <- Sys.time()
end_time - start_time

```
